{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spectacular-screening",
   "metadata": {},
   "source": [
    "# Temporal CNN Model Evaluation and Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medieval-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "#Script uses conda environment 'Python 3.8 (earthengine-gcloud)'\n",
    "\n",
    "# Packages\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import datetime\n",
    "import pprint\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from glob import glob\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Tensorflow & Keras\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) \n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-trade",
   "metadata": {},
   "source": [
    "# Load Trained TemporalCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a trained model\n",
    "model = keras.models.load_model(r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/temporalCNN/Archi7/TempCNN_100epochs_latlongenc_classweightinvfreq_nov202023-1.h5')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-nerve",
   "metadata": {},
   "source": [
    "# Read and Format Testing Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Testing Data\n",
    "\n",
    "# Read testing set dataframe\n",
    "test_df = pd.DataFrame(pd.read_csv(\"/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/datasets_oct23/test_spurge_landcover_landsat_spectral_allyears_69ksample_locations_MN.csv\"))\n",
    "test_df.head()\n",
    "#print(test_df.shape)\n",
    "nchannels = 7 #-- B G NDVI NIR Red SWIR1 SWIR2\n",
    "\n",
    "# Select spectral data (first 63 columns)\n",
    "batch_X = test_df.iloc[:, 1:64].to_numpy()\n",
    "batch_X_spectral = batch_X.reshape(batch_X.shape[0],int(batch_X.shape[1]/nchannels),nchannels)\n",
    "#print(batch_X_spectral[0])\n",
    "#print(batch_X_spectral.shape)\n",
    "\n",
    "# Select latitude/longitude coordinates (get last 3 columns, remove last 1 (class) column)\n",
    "batch_X_coords = test_df.iloc[:, -3:].iloc[:, :-1].to_numpy()\n",
    "#print(batch_X_coords.shape)\n",
    "\n",
    "# Add X data(lat/long coordinates and spectral data) as list to X_test\n",
    "# Add Y data(class) to Y_test\n",
    "X_test = [batch_X_coords, batch_X_spectral]\n",
    "\n",
    "# Select class data from last column\n",
    "y_test = np.asarray(test_df.iloc[:, -1]).astype(int)\n",
    "\n",
    "\n",
    "# Get unique class labels\n",
    "unique_classes = np.unique(y_test)\n",
    "print(unique_classes)\n",
    "# Create a mapping dictionary\n",
    "class_mapping = {class_label: index for index, class_label in enumerate(unique_classes)}\n",
    "# Map the class indices to the new numeric indices\n",
    "y_test_mapped = np.array([class_mapping[class_label] for class_label in y_test])\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "y_test_one_hot = to_categorical(y_test_mapped, num_classes=len(unique_classes))\n",
    "\n",
    "# Validate data are formatted correctly\n",
    "# X_test[0] are lat/long coordinate pairs, (nsamples, 2)\n",
    "# X_test[1] are 7 spectral bands across 9 timesteps (nsamples, 9, 7)\n",
    "# y_test_one_hot are one-hot encoded class labels (nsamples, num_classes)\n",
    "print(X_test[0].shape, X_test[1].shape, y_test_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-phenomenon",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance with Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model prediction\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Predict the model on withheld testing dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_pred_flat = y_pred.flatten()\n",
    "y_pred_flat = y_pred_flat.astype(int)\n",
    "\n",
    "y_test = y_test.astype(int)    \n",
    "\n",
    "# Reclassify y_test class values to match model predictions starting from 0\n",
    "y_test[y_test==11] = 0 #Open Water\n",
    "y_test[y_test==21] = 1 #Developed Open Space\n",
    "y_test[y_test==22] = 2 #Developed Low Intensity\n",
    "y_test[y_test==23] = 3 #Developed Medium Intensity\n",
    "y_test[y_test==24] = 4 #Developed High Intensity\n",
    "y_test[y_test==31] = 5 #Barren Land\n",
    "y_test[y_test==41] = 6 #Deciduous Forest\n",
    "y_test[y_test==42] = 7 #Evergreen Forest\n",
    "y_test[y_test==43] = 8 #Mixed Forest\n",
    "y_test[y_test==52] = 9 #Shrub/Scrub\n",
    "y_test[y_test==71] = 10 #Grassland/Herbaceous\n",
    "y_test[y_test==81] = 11 #Pasture/Hay\n",
    "y_test[y_test==82] = 12 #Cultivated Crops\n",
    "y_test[y_test==90] = 13 #Woody Wetlands\n",
    "y_test[y_test==95] = 14 #Emergent Herbaceous Wetlands\n",
    "y_test[y_test==99] = 15 #Leafy Spurge\n",
    "\n",
    "y_test_flat = y_test.flatten()\n",
    "\n",
    "#Count number of classes in the testing dataset\n",
    "unique_vals, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "class_names = [\"Open Water\", \"Developed Open Space\", \"Developed Low Intensity\", \"Developed Medium Intensity\",\n",
    "              \"Developed High Intensity\", \"Barren Land\", \"Deciduous Forest\", \"Evergreen Forest\", \"Mixed Forest\",\n",
    "              \"Shrub/Scrub\", \"Grassland/Herbaceous\", \"Pasture/Hay\", \"Cultivated Crops\", \"Woody Wetlands\", \"Emerg. Herb. Wetlands\",\n",
    "              \"Leafy Spurge\"]\n",
    "\n",
    "class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "c = multilabel_confusion_matrix(y_test_flat, y_pred_flat, labels = class_labels)\n",
    "model_output_metrics = []\n",
    "for i in range(len(class_labels)):\n",
    "    tn=c[i, 0, 0]\n",
    "    tp=c[i, 1, 1]\n",
    "    fn=c[i, 1, 0]\n",
    "    fp=c[i, 0, 1]\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    TPR_Sens_Recall = tp/(tp+fn)\n",
    "    TNR_Spec = tn/(tn+fp)\n",
    "    FPR = fp/(fp+tn)\n",
    "    FNR = fn/(fn+tp)\n",
    "    precision = tp/(tp+fp)\n",
    "    jaccard = tp/(tp+fp+fn)\n",
    "    F05 = (1.25 * precision * TPR_Sens_Recall) / ((1.25 * precision) + TPR_Sens_Recall)\n",
    "    F1 = (2 * precision * TPR_Sens_Recall) / (precision + TPR_Sens_Recall)\n",
    "    F2 = (5 * precision * TPR_Sens_Recall) / ((5 * precision) + TPR_Sens_Recall)\n",
    "    outputs = [class_names[i], counts[i], tp, tn, fp, fn, accuracy, TPR_Sens_Recall, TNR_Spec, FPR, FNR, precision, jaccard, F1]\n",
    "    model_output_metrics.append(outputs)\n",
    "\n",
    "# Print and format outputs\n",
    "print(tabulate(model_output_metrics, floatfmt=\".2f\", headers=[\"Class Name\", \"Num Points\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"TPR/Sens/Recall\", \"TNR/Spec\", \"FPR\", \"FNR\", \"Precision\", \"Jaccard\", \"F1\"]))\n",
    "\n",
    "#Save tabulated results to file\n",
    "#with open(res_file, 'w') as f:\n",
    "#    f.write(tabulate(model_output_metrics, floatfmt=\".2f\", headers=[\"Class Name\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"TPR/Sens/Recall\", \"TNR/Spec\", \"FPR\", \"FNR\", \"Precision\", \"Jaccard\", \"F1\"]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c3677-5562-4607-9f75-722de8968e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "improving-civilization",
   "metadata": {},
   "source": [
    "# Plot Training History of Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in Model Training History File (if Available)\n",
    "model_history_path = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/temporalCNN/Archi6/trainingHistory-SB-latlong-spurgespatialthin001-blockcrossvalidation-noarchi6-norun-0.txt'\n",
    "\n",
    "# Read data from the file\n",
    "with open(model_history_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract data columns\n",
    "epochs = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "for line in lines:\n",
    "    values = [float(x) for x in line.split()]\n",
    "    epochs.append(values[-1])\n",
    "    train_loss.append(values[0])\n",
    "    val_loss.append(values[1])\n",
    "    train_accuracy.append(values[2])\n",
    "    val_accuracy.append(values[3])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting Training Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Training Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-tobacco",
   "metadata": {},
   "source": [
    "# Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, cohen_kappa_score, accuracy_score, f1_score, precision_score, recall_score, jaccard_score, fbeta_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tabulate import tabulate\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        classes,\n",
    "        test_name,\n",
    "        normalize=False,\n",
    "        set_title=False,\n",
    "        save_fig=False,\n",
    "        cmap=plt.cm.Blues\n",
    "):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    if set_title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    # and save it to log file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "        #with open(f'F:/PlanetScope_LSTM_Imagery/reports/logs_and_plots/{test_name}_log.txt', 'ab') as f:\n",
    "        #    f.write(b'\\nNormalized confusion matrix\\n')\n",
    "        #    np.savetxt(f, cm, fmt='%.3f')\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        #with open(f'F:/PlanetScope_LSTM_Imagery/reports/logs_and_plots/{test_name}_log.txt', 'ab') as f:\n",
    "        #    f.write(b'\\nConfusion matrix, without normalization\\n')\n",
    "        #    np.savetxt(f, cm, fmt='%7u')\n",
    "\n",
    "    #print(cm)\n",
    "    #cm = cm[1:10]\n",
    "    #cm = cm[:,1:]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    if normalize:\n",
    "        im.set_clim(0., 1.)     # fixes missing '1.0' tick at top of colorbar\n",
    "    cb = ax.figure.colorbar(im, ax=ax)\n",
    "    if normalize:\n",
    "        cb.set_ticks(np.arange(0., 1.2, 0.2))\n",
    "        cb.set_ticklabels([f'{i/5:.1f}' for i in range(6)])\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title if set_title else None,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    ax.set_ylim(len(cm)-0.5, -0.5)\n",
    "    ax.xaxis.label.set_size(10)\n",
    "    ax.yaxis.label.set_size(10)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if np.round(cm[i, j], 2) > 0.:\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            else:\n",
    "                ax.text(j, i, 'â€“',\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_fig:\n",
    "        if normalize:\n",
    "            plt.savefig(f'F:/PlanetScope_LSTM_Imagery/reports/logs_and_plots/{test_name}_cm_normal.pdf')\n",
    "        else:\n",
    "            plt.savefig(f'F:/PlanetScope_LSTM_Imagery/reports/logs_and_plots/{test_name}_cm_non_normal.pdf')\n",
    "    return fig, ax, cm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inv_category_dict = {0:\"Open Water\", 1:\"Developed Open Space\", 2:\"Developed Low Intensity\", 3:\"Developed Medium Intensity\", 4:\"Developed High Intensity\", 5:\"Barren Land\", \n",
    "                     6:\"Deciduous Forest\", 7:\"Evergreen Forest\", 8:\"Mixed Forest\", 9:\"Shrub/Scrub\", 10:\"Grassland/Herbaceous\", 11:\"Pasture/Hay\", \n",
    "                     12:\"Cultivated Crops\", 13:\"Woody Wetlands\", 14:\"Emerg. Herb. Wetlands\", 15:\"Leafy Spurge\"}\n",
    "\n",
    "class_names = [inv_category_dict[i] for i in np.arange(0, 15)]\n",
    "\n",
    "# Calculate confusion matrix\n",
    "class_names_list = [\"Open Water\", \"Developed Open Space\", \"Developed Low Intensity\", \"Developed Medium Intensity\",\n",
    "             \"Developed High Intensity\", \"Barren Land\", \"Deciduous Forest\", \"Evergreen Forest\", \"Mixed Forest\",\n",
    "             \"Shrub/Scrub\", \"Grassland/Herbaceous\", \"Pasture/Hay\", \"Cultivated Crops\", \"Woody Wetlands\", \"Emerg. Herb. Wetlands\",\n",
    "             \"Leafy Spurge\"]\n",
    "\n",
    "#class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "# save plot of normalized cm\n",
    "cm = plot_confusion_matrix(\n",
    "    y_test_flat,\n",
    "    y_pred_flat,\n",
    "    classes=class_names_list,\n",
    "    test_name=\"myModel\",\n",
    "    normalize=True,\n",
    "    save_fig=False\n",
    ")\n",
    "\n",
    "conf_df = pd.DataFrame(cm[2], columns = class_names_list)\n",
    "\n",
    "#np.savetxt(conf_file, conf_df, fmt='%6f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-january",
   "metadata": {},
   "source": [
    "# Define Model Prediction Mosaic Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Model Predictions of Leafy Spurge\n",
    "# To Generate .TIF Predictions, Run Inference on Landsat Tiles in r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles'\n",
    "# Using slurm to submit predictRasters-spurgesoftmax-latlon-encoding.py Python script that generates predictions, and gdal_merge tool to mosaic predictions\n",
    "\n",
    "# Prediction from Landsat imagery between 2000 - 2002\n",
    "# Argmax contains only Leafy Spurge class, data range from 0-1\n",
    "prediction_2001_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2001/merged_predictions_argmax_landsat_temporalcnn_2001_dec23.tif'\n",
    "# Softmax contains all class values predicted from model as integers [0-15]\n",
    "prediction_2001_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2001/merged_predictions_softmax_landsat_temporalcnn_2001_dec23.tif'\n",
    "\n",
    "\n",
    "# Prediction from Landsat imagery between 2003 - 2005\n",
    "prediction_2004_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2004/merged_predictions_argmax_landsat_temporalcnn_2004_dec23.tif'\n",
    "prediction_2004_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2004/merged_predictions_softmax_landsat_temporalcnn_2004_dec23.tif'\n",
    "\n",
    "\n",
    "# Prediction from Landsat imagery between 2006 - 2008\n",
    "prediction_2007_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2007/merged_predictions_argmax_landsat_temporalcnn_2007_dec23.tif'\n",
    "prediction_2007_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2007/merged_predictions_softmax_landsat_temporalcnn_2007_dec23.tif'\n",
    "\n",
    "\n",
    "# Prediction from Landsat imagery between 2009 - 2011\n",
    "prediction_2010_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2010/merged_predictions_argmax_landsat_temporalcnn_2010_dec23.tif'\n",
    "prediction_2010_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2010/merged_predictions_softmax_landsat_temporalcnn_2010_dec23.tif'\n",
    "\n",
    "\n",
    "# Prediction from Landsat imagery between 2013 - 2015\n",
    "prediction_2014_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2014/merged_predictions_argmax_landsat_temporalcnn_2014_dec23.tif'\n",
    "prediction_2014_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2014/merged_predictions_softmax_landsat_temporalcnn_2014_dec23.tif'\n",
    "\n",
    "\n",
    "# Prediction from Landsat imagery between 2015 - 2017\n",
    "prediction_2016_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2016/merged_predictions_argmax_landsat_temporalcnn_2016_dec23.tif'\n",
    "prediction_2016_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2016/merged_predictions_softmax_landsat_temporalcnn_2016_dec23.tif'\n",
    "\n",
    "\n",
    "# Prediction from Landsat imagery between 2018 - 2020\n",
    "prediction_2019_argmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2019/merged_predictions_argmax_landsat_temporalcnn_2019_dec23.tif'\n",
    "prediction_2019_softmax = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2019/merged_predictions_softmax_landsat_temporalcnn_2019_dec23.tif'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-transmission",
   "metadata": {},
   "source": [
    "# Plot one prediction mosaic raster for leafy spurge (probability values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predicted Probability of Leafy Spurge Raster\n",
    "\n",
    "# Choose one of the raster files to plot\n",
    "selected_raster = prediction_2004_argmax  # Replace with the desired file path\n",
    "\n",
    "# Read and plot the selected raster\n",
    "with rasterio.open(selected_raster) as src:\n",
    "    data = src.read(1, masked=True)\n",
    "    data.shape\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    show(data, transform=src.transform, cmap='viridis', title=f\"{selected_raster}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-universal",
   "metadata": {},
   "source": [
    "# Plot one prediction mosaic raster for leafy spurge (classification values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Land Cover CLasses Raster\n",
    "\n",
    "# Choose one of the raster files to plot\n",
    "selected_raster = prediction_2001_softmax  # Replace with the desired file path\n",
    "\n",
    "# Read and plot the selected raster\n",
    "with rasterio.open(selected_raster) as src:\n",
    "    data = src.read(1, masked=True)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    show(data, transform=src.transform, cmap='viridis', title=f\"{selected_raster}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-madison",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance Based on Leafy Spurge from 2021 - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Leafy Spurge occurrence records from 2021, 2022, and 2023\n",
    "\n",
    "spurge_data = r'/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/datasets_oct23/leafy-spurge-csv/eddmaps_inaturalist_spurge_observations_filtered_combined_october2023_minnesota.csv'\n",
    "\n",
    "# Read in .CSV file\n",
    "spurge_df = pd.read_csv(spurge_data)\n",
    "\n",
    "# Extract latitude, longitude, and ObsDate columns from the DataFrame\n",
    "latitude = spurge_df['Latitude']\n",
    "longitude = spurge_df['Longitude']\n",
    "obs_date = pd.to_datetime(spurge_df['ObsDate'], errors='coerce')  # Convert 'ObsDate' to datetime\n",
    "\n",
    "# Select only records where 'ObsDate' contains the years 2021 to 2023\n",
    "selected_records = spurge_df[(obs_date >= '2021-01-01') & (obs_date <= '2023-12-31')]\n",
    "\n",
    "selected_records_old = spurge_df[obs_date <= '2021-01-01']\n",
    "\n",
    "# Subset records by dates used to develop models\n",
    "selected_records_2000_2002 = spurge_df[(obs_date >= '2000-01-01') & (obs_date <= '2002-12-31')]\n",
    "\n",
    "selected_records_2003_2005 = spurge_df[(obs_date >= '2003-01-01') & (obs_date <= '2005-12-31')]\n",
    "\n",
    "selected_records_2006_2008 = spurge_df[(obs_date >= '2006-01-01') & (obs_date <= '2008-12-31')]\n",
    "\n",
    "selected_records_2009_2011 = spurge_df[(obs_date >= '2009-01-01') & (obs_date <= '2011-12-31')]\n",
    "\n",
    "selected_records_2013_2015 = spurge_df[(obs_date >= '2013-01-01') & (obs_date <= '2015-12-31')]\n",
    "\n",
    "selected_records_2015_2017 = spurge_df[(obs_date >= '2015-01-01') & (obs_date <= '2017-12-31')]\n",
    "\n",
    "selected_records_2018_2020 = spurge_df[(obs_date >= '2018-01-01') & (obs_date <= '2020-12-31')]\n",
    "\n",
    "# Read in the shapefile\n",
    "shapefile_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/shapefiles/Minnesota_Shapefile.shp' \n",
    "shapefile = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Plot the shapefile\n",
    "shapefile.plot(color='gray', figsize=(20, 12))\n",
    "\n",
    "# Plot all records in blue\n",
    "plt.scatter(longitude, latitude, color='blue', alpha=0.6, edgecolors='w', s=50, label='Other Records')  # All records in blue\n",
    "\n",
    "# Plot selected records in red\n",
    "plt.scatter(selected_records['Longitude'], selected_records['Latitude'], color='red', alpha=0.6, edgecolors='w', s=50, label='2021-2023 Records')  # Selected records in red\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Longitude', fontsize=20)\n",
    "plt.ylabel('Latitude', fontsize=20)\n",
    "plt.title('Leafy Spurge Occurrences', fontsize=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d7d80-593f-47fe-98c1-1883b0489283",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-executive",
   "metadata": {},
   "source": [
    "# Extract Predicted Leafy Spurge Values (0-1) from 2019 Raster using the 2021 - 2023 Leafy Spurge Occurrences\n",
    "\n",
    "- How well are leafy spurge occurrences from 2021-2023 predicted by the 2019 Landsat imagery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the raster file\n",
    "raster_file_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2019/merged_predictions_argmax_landsat_temporalcnn_2019_dec23.tif'\n",
    "with rasterio.open(raster_file_path) as src:\n",
    "    # Extract raster values at points\n",
    "    #selected_values_newspurge = [x[0] for x in src.sample(zip(selected_records['Longitude'], selected_records['Latitude']))]\n",
    "    selected_values = [x[0] for x in src.sample(zip(selected_records['Longitude'], selected_records['Latitude']))]\n",
    "\n",
    "    \n",
    "# Create stacked bar plots\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.hist(selected_values, bins=50, color=['red'], alpha=0.7, label=['Leafy Spurge (2021 - 2023)'], stacked=True)\n",
    "plt.xlabel('Predicted Probability of Leafy Spurge', fontsize=18)  # Increase font size for x-axis label\n",
    "plt.ylabel('Number of Records', fontsize=18)  # Increase font size for y-axis label\n",
    "plt.title('Bar Plot of Probability Values for Leafy Spurge Records', fontsize=18)  # Increase font size for title\n",
    "plt.xticks(fontsize=18)  # Increase font size for x-axis ticks\n",
    "plt.yticks(fontsize=18)  # Increase font size for y-axis ticks\n",
    "plt.legend(fontsize=18)  # Add legend with increased font size\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024cd27-1d3d-4304-b181-3bc545875f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bright-tissue",
   "metadata": {},
   "source": [
    "# Extract Predicted Class Values (0-16) from 2019 Raster using the 2021 - 2023 Leafy Spurge Occurrences\n",
    "\n",
    "- How well does the model classify leafy spurge occurrences from 2021 - 2023 given the prediction from the 2019 Landsat imagery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raster file\n",
    "raster_file_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2019/merged_predictions_softmax_landsat_temporalcnn_2019_dec23.tif'\n",
    "with rasterio.open(raster_file_path) as src:\n",
    "    # Extract raster values at points\n",
    "    #selected_values_softmax = [x[0] for x in src.sample(zip(selected_records['Longitude'], selected_records['Latitude']))]\n",
    "    selected_values = [x[0] for x in src.sample(zip(selected_records['Longitude'], selected_records['Latitude']))]\n",
    "    \n",
    "\n",
    "class_names = [\"Open Water\", \"Developed Open Space\", \"Developed Low Intensity\", \"Developed Medium Intensity\",\n",
    "             \"Developed High Intensity\", \"Barren Land\", \"Deciduous Forest\", \"Evergreen Forest\", \"Mixed Forest\",\n",
    "             \"Shrub/Scrub\", \"Grassland/Herbaceous\", \"Pasture/Hay\", \"Cultivated Crops\", \"Woody Wetlands\", \"Emerg. Herb. Wetlands\",\n",
    "             \"Leafy Spurge\"]\n",
    "    \n",
    "# Create a bar plot of each category\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(16), [selected_values.count(i) for i in range(16)], color='red', alpha=0.7)\n",
    "plt.xticks(range(16), class_names, rotation=45, ha='right', fontsize=12)  # Increase font size for x-axis labels\n",
    "plt.yticks(fontsize=12)  # Increase font size for y-axis labels\n",
    "plt.xlabel('Land Cover Class', fontsize=18)  # Increase font size for x-axis label\n",
    "plt.ylabel('Frequency', fontsize=18)  # Increase font size for y-axis label\n",
    "plt.title('Bar Plot of Land Cover Classes for 2018 - 2020 Records', fontsize=16)  # Increase font size for title\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raster file\n",
    "raster_file_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/minnesota_landsat_tiles/predictions_2019/merged_predictions_softmax_landsat_temporalcnn_2019_dec23.tif'\n",
    "with rasterio.open(raster_file_path) as src:\n",
    "    # Extract raster values at points\n",
    "    selected_values_softmax = [x[0] for x in src.sample(zip(selected_records['Longitude'], selected_records['Latitude']))]\n",
    "    selected_values_oldsoftmax = [x[0] for x in src.sample(zip(selected_records_old['Longitude'], selected_records_old['Latitude']))]\n",
    "\n",
    "# Create a stacked bar plot for each category\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(16), [selected_values_softmax.count(i) + selected_values_oldsoftmax.count(i) for i in range(16)], color='red', alpha=0.7, label='Leafy Spurge (2021 - 2023)')  # Blue bars for new softmax\n",
    "plt.bar(range(16), [selected_values_oldsoftmax.count(i) for i in range(16)], bottom=[selected_values_softmax.count(i) for i in range(16)], color='blue', alpha=0.7, label='Leafy Spurge (2000 - 2020)')  # Red bars for old softmax\n",
    "plt.xticks(range(16), class_names, rotation=45, ha='right', fontsize=12)  # Increase font size for x-axis labels\n",
    "plt.yticks(fontsize=12)  # Increase font size for y-axis labels\n",
    "plt.xlabel('Land Cover Class', fontsize=18)  # Increase font size for x-axis label\n",
    "plt.ylabel('Frequency', fontsize=18)  # Increase font size for y-axis label\n",
    "plt.title('Predicted Land Cover Classes given Leafy Spurge Records', fontsize=16)  # Increase font size for title\n",
    "plt.legend(fontsize=16)  # Add legend with increased font size\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-affect",
   "metadata": {},
   "source": [
    "# Extract Predicted Leafy Spurge Values (0-1) from 2019 Raster using the Leafy Spurge Polygons from 2019 - 2023 in Twin Cities Region\n",
    "\n",
    "- How well are leafy spurge populations from 2019-2023 predicted by the 2019 Landsat imagery?\n",
    "- Does probability of detection relate to population size (from EddMaps polygons)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16a8ac-d576-46e2-9d05-cac0daac7b8a",
   "metadata": {},
   "source": [
    "# Evaluate predicted probability of leafy spurge with surveyed EddMaps polygons covering Twin Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "\n",
    "# Read in the leafy spurge polygons shapefile\n",
    "spurge_shapefile_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/shapefiles/leafy-spurge-eddmaps-polygons-dec23.shp' \n",
    "spurge_shapefile = gpd.read_file(spurge_shapefile_path)\n",
    "\n",
    "# Convert 'ObsDate' to datetime\n",
    "spurge_shapefile['ObsDate'] = pd.to_datetime(spurge_shapefile['ObsDate'], errors='coerce')\n",
    "\n",
    "# Filter polygons based on conditions\n",
    "filtered_spurge_shapefile = spurge_shapefile[\n",
    "    (spurge_shapefile['ObsDate'].dt.year.isin([2018, 2019, 2020, 2021, 2022, 2023])) &\n",
    "    (spurge_shapefile['Status'] == 'Positive') &\n",
    "    (spurge_shapefile['OccStatus'] == 'Detected') &\n",
    "    (~spurge_shapefile['InfestAcre'].isnull()) &\n",
    "    (spurge_shapefile['InfestAcre'] > 0)\n",
    "]\n",
    "\n",
    "# Define the bounding box coordinates\n",
    "bbox = box(minx=-93.8498, miny=44.5495, maxx=-92.8248, maxy=45.2814)\n",
    "\n",
    "# Apply spatial filter\n",
    "cropped_spurge_shapefile = filtered_spurge_shapefile.cx[bbox.bounds[0]:bbox.bounds[2], bbox.bounds[1]:bbox.bounds[3]]\n",
    "\n",
    "# Print summary information\n",
    "print(f\"Original shapefile has {len(spurge_shapefile)} polygons.\")\n",
    "print(f\"After filtering with date, status, and area, the shapefile has {len(filtered_spurge_shapefile)} polygons.\")\n",
    "print(f\"After filtering with spatial location, the shapefile has {len(cropped_spurge_shapefile)} polygons.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3b935-2a1e-4f98-a3ad-645d581b21f0",
   "metadata": {},
   "source": [
    "# Evaluate predicted probability of leafy spurge with surveyed EddMaps polygons covering entire state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, crop the leafy spurge polygons by the entire state of Minnesota\n",
    "from geopandas.tools import overlay\n",
    "\n",
    "# Read in the shapefile representing the state boundaries of Minnesota\n",
    "state_shapefile_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/shapefiles/Minnesota_Shapefile.shp'\n",
    "state_shapefile = gpd.read_file(state_shapefile_path)\n",
    "\n",
    "# Read in the leafy spurge polygons shapefile\n",
    "spurge_shapefile_path = '/panfs/jay/groups/31/moeller/shared/leafy-spurge-demography/shapefiles/leafy-spurge-eddmaps-polygons-dec23.shp' \n",
    "spurge_shapefile = gpd.read_file(spurge_shapefile_path)\n",
    "\n",
    "# Convert 'ObsDate' to datetime\n",
    "spurge_shapefile['ObsDate'] = pd.to_datetime(spurge_shapefile['ObsDate'], errors='coerce')\n",
    "\n",
    "# Filter polygons based on conditions\n",
    "filtered_spurge_shapefile = spurge_shapefile[\n",
    "    (spurge_shapefile['ObsDate'].dt.year.isin([2018, 2019, 2020, 2021, 2022, 2023])) &\n",
    "    (spurge_shapefile['Status'] == 'Positive') &\n",
    "    (spurge_shapefile['OccStatus'] == 'Detected') &\n",
    "    (~spurge_shapefile['InfestAcre'].isnull()) &\n",
    "    (spurge_shapefile['InfestAcre'] > 0)\n",
    "]\n",
    "\n",
    "# Perform overlay to crop spurge_shapefile by state_shapefile\n",
    "cropped_spurge_shapefile = overlay(filtered_spurge_shapefile, state_shapefile, how='intersection')\n",
    "\n",
    "# Print summary information\n",
    "print(f\"Original shapefile has {len(spurge_shapefile)} polygons.\")\n",
    "print(f\"After filtering with date, status, and area, the shapefile has {len(filtered_spurge_shapefile)} polygons.\")\n",
    "print(f\"After cropping by the state boundaries, the shapefile has {len(cropped_spurge_shapefile)} polygons.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'ObsYear' to store the year of observation\n",
    "cropped_spurge_shapefile['ObsYear'] = cropped_spurge_shapefile['ObsDate'].dt.year\n",
    "\n",
    "# Count the number of observations per year\n",
    "observations_per_year = cropped_spurge_shapefile.groupby('ObsYear').size()\n",
    "\n",
    "print(observations_per_year)\n",
    "\n",
    "# Plot a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "observations_per_year.plot(kind='bar', color='blue', alpha=0.7)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Number of Observations per Year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217ae9f-4039-4af1-9bef-f72682f50792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_spurge_shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new column 'InfestSquareMeters' and convert 'InfestAcre' to square meters\n",
    "cropped_spurge_shapefile['InfestSquareMeters'] = cropped_spurge_shapefile['InfestAcre'] * 4046.86  # 1 acre = 4046.86 square meters\n",
    "\n",
    "# Log-transform 'InfestSquareMeters'\n",
    "cropped_spurge_shapefile['LogInfestSquareMeters'] = np.log1p(cropped_spurge_shapefile['InfestSquareMeters'])\n",
    "\n",
    "\n",
    "# Plot a histogram of the 'InfestAcre' field\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cropped_spurge_shapefile['InfestSquareMeters'], bins=10000, color='blue', alpha=0.7)\n",
    "plt.xlabel('Square Meters', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.title('Histogram of Infested Square Meters', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "np.min(cropped_spurge_shapefile['InfestSquareMeters'])\n",
    "np.mean(cropped_spurge_shapefile['InfestSquareMeters'])\n",
    "np.max(cropped_spurge_shapefile['InfestSquareMeters'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-blood",
   "metadata": {},
   "source": [
    "# Extract Predicted Leafy Spurge Probability from Each Polygon of Survyed Leafy Spurge From 2018 - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Use zonal_stats to extract raster values for each polygon\n",
    "zs_result = zonal_stats(cropped_spurge_shapefile, prediction_2019_argmax, stats='max', geojson_out=True)\n",
    "\n",
    "# Create a new GeoDataFrame from the zonal_stats result\n",
    "result_df = gpd.GeoDataFrame.from_features(zs_result, crs=cropped_spurge_shapefile.crs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-sessions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "pixel_resolution = 30\n",
    "\n",
    "# Calculate the number of pixels\n",
    "result_df['NumPixels'] = result_df['InfestSquareMeters'] / (pixel_resolution ** 2)\n",
    "\n",
    "# Plot a scatter plot with 'Number of Pixels'\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Scatter plot with larger points\n",
    "plt.scatter(result_df['NumPixels'], result_df['max'], alpha=0.6, edgecolors='w', s=100, c='blue')\n",
    "\n",
    "# Increase font size for axis labels and title\n",
    "plt.xlabel('Leafy Spurge Population Size (Num Landsat 30x30m Px)', fontsize=30)\n",
    "plt.ylabel('Mean Predicted Value', fontsize=30)\n",
    "plt.title('Scatter Plot Leafy Spurge Prediction vs. Population Size', fontsize=30)\n",
    "\n",
    "# Increase font size for tick labels\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Adjust the x-axis limit as needed\n",
    "plt.xlim(0, 25)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "pixel_resolution = 30\n",
    "\n",
    "# Calculate the number of pixels\n",
    "result_df['NumPixels'] = result_df['InfestSquareMeters'] / (pixel_resolution ** 2)\n",
    "\n",
    "# Define the bins for categorization\n",
    "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, np.inf]  # Adjust the bin edges as needed\n",
    "\n",
    "# Create a new categorical column 'NumPixelsCategory' based on the bins\n",
    "result_df['NumPixelsCategory'] = pd.cut(result_df['NumPixels'], bins=bins, labels=['<1', '1', '2', '3', '4', '5', '6', '7', '8', '9', '>10'])\n",
    "\n",
    "# Plot a scatter plot with categorical x-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = plt.scatter(result_df['NumPixels'], result_df['max'], alpha=0.6, edgecolors='w', s=50, c=result_df['NumPixelsCategory'].cat.codes, cmap='viridis')\n",
    "plt.xlabel('Number of Pixels')\n",
    "plt.ylabel('Average Prediction (Argmax)')\n",
    "plt.title('Scatter Plot of Number of Pixels vs. Average Prediction')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a legend for the categories\n",
    "legend = plt.legend(*scatter.legend_elements(), title='NumPixelsCategory')\n",
    "plt.gca().add_artist(legend)\n",
    "\n",
    "# Adjust the x-axis limit as needed\n",
    "plt.xlim(0,25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-static",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given values\n",
    "pixel_resolution = 30\n",
    "\n",
    "# Calculate the number of pixels\n",
    "result_df['NumPixels'] = result_df['InfestSquareMeters'] / (pixel_resolution ** 2)\n",
    "\n",
    "# Define the bins for categorization\n",
    "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, np.inf]  # Adjust the bin edges as needed\n",
    "\n",
    "# Create a new categorical column 'NumPixelsCategory' based on the bins\n",
    "result_df['NumPixelsCategory'] = pd.cut(result_df['NumPixels'], bins=bins, labels=['<1', '1', '2', '3', '4', '5', '6', '7', '8', '9', '>10'])\n",
    "\n",
    "# Convert 'NumPixelsCategory' to categorical with a custom order\n",
    "category_order = ['<1', '1', '2', '3', '4', '5', '6', '7', '8', '9', '>10']\n",
    "result_df['NumPixelsCategory'] = pd.Categorical(result_df['NumPixelsCategory'], categories=category_order, ordered=True)\n",
    "\n",
    "# Create boxplots for each category\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Larger elements in the boxplot\n",
    "sns.boxplot(x='NumPixelsCategory', y='max', data=result_df, width=0.7, linewidth=2)\n",
    "\n",
    "# Increase font size for axis labels and title\n",
    "plt.xlabel('Leafy Spurge Population Size (Num Landsat 30x30m Px)', fontsize=30)\n",
    "plt.ylabel('Max Predicted Value', fontsize=30)\n",
    "plt.title('Boxplots of Max Prediction for Number of Pixels Categories', fontsize=30)\n",
    "\n",
    "# Increase font size for tick labels\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-comedy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-pursuit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-original",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-provider",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (earthengine-gcloud)",
   "language": "python",
   "name": "earthengine_gcloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
